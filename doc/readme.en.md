
[ðŸ‡°ðŸ‡· í•œêµ­ì–´](https://github.com/kkuoky/AiMyIdea)) | [ðŸ‡¬ðŸ‡§ English](https://github.com/kkuoky/AiMyIdea/doc/readme.en.md))


# "Elements of AI - part2 Building AI course" Final Project

**[buildingai.elementsofai.com](https://buildingai.elementsofai.com/)**

## Summary

This project is an **AI classification model** trained to distinguish between images generated by AI and those created by humans. This model analyzes an uploaded image to determine if it was synthesized by AI (AI-generated) or created by a person (Human-made).

## Background

Recently, with the advancement of generative AI models like Midjourney and Stable Diffusion, it has become increasingly difficult to distinguish between AI-made images and actual photographs or digital creations by human artists.

This phenomenon presents the following problems:

- **Fake News:** Fabricated AI images, appearing as real events, can distort facts and be used to incite people.
    
- **Infringement on Creators' Intellectual Property:** First, AI projects that use data for training without the consent of the original copyright holders are in violation of copyright law. Second, the act of passing off AI-generated images as human creations can impact the creativity and livelihood of new creators.
    
- **Decline in Social Trust:** Already, user-generated multimedia services like YouTube are flooded with AI-generated content. The inability to distinguish truth from falsehood can lead to a decline in the trustworthiness of online content and an increase in noise, raising the social cost of restoring trust.
    

This project was started with the objective of addressing the severity of these issues and the need for a technical tool to ensure the transparency and authenticity of digital content.

## How is it used?

This solution will be released as an open-source project intended for on-premise use.

1. A user (e.g., service provider, news editor, multimedia editor, or general user) uploads an image or provides a web link for the image they wish to authenticate.
    
2. The pre-trained AI model analyzes the image to probabilistically determine if it is AI-generated.
    
3. The AI model returns a probabilistic result, such as "AI Generation Probability: 51%" or "Human-Made Probability: 95%."
    

This tool can be usefully employed in situations where news organizations need to verify press photos, art competitions need to screen for AI-generated works, or social media platforms need to filter Deepfake content.

## Data sources and AI methods

This model will be designed with a **CNN (Convolutional Neural Network)** architecture based on **Supervised Learning**. CNNs are highly suitable for image classification tasks as they can efficiently learn the spatial features of an image.

The training data will be collected from free image sites and generated by AI (like Stable Diffusion) for initial training. Subsequently, the model will be upgraded by collecting a small percentage of images submitted by users during the service's operation, and new model weights will be continuously released.

1. **Human-Made Images:** Datasets of real photographs (e.g., COCO, Unsplash) and digital artwork by human artists, as well as images submitted by users that have an AI generation probability of 20% or less.
    
2. **AI-Generated Images:** Large-scale image sets generated by various modern generative models (Stable Diffusion, Midjourney, DALL-E 3, etc.) and images submitted by users with an AI generation probability of 80% or more.
    

|**AI Method**|**Description**|
|---|---|
|**CNN Classifier**|A neural network that learns the subtle patterns and statistical differences in images to classify them into two classes (AI vs. Human).|
|**Data Augmentation**|Techniques such as rotating, scaling, and compressing images are used to ensure dataset diversity.|

## Challenges

This project is not perfect as it faces the following practical limitations and ethical issues:

- **An "Arms Race" (Cat-and-Mouse Game):** Even if this detection technology learns AI-generated patterns, future AI generation models will evolve to evade this detection (much like the Generator and Discriminator in a GAN model). Therefore, the detection model requires continuous updates, and the quality of data (clearly distinct human vs. AI images) and an objective method to secure it are crucial.
    
- **Vulnerability to Post-processing:** The model's judgment may be naive when faced with human post-processing, such as an AI-generated image being retouched by a person or having filters applied in an image tool.
    
- **Ethical Problem (False Positives):** The greatest risk is a 'false positive' AI determination. If this model incorrectly classifies a human creator's work as "AI-generated," it can cause severe damage to that artist's reputation and intellectual property. Therefore, this tool must only be used as a supplementary reference, not as a final verdict. All critical decisions must ultimately be made by a human.
    

## What next?

This project can be expanded in the following ways in the future:

- **Expanding Detection Content:** The model could be expanded to detect not only images but also **AI-generated videos (Deepfakes)** and **AI-generated audio**, though this will be a very difficult task.
    
- **Expanding Detection Data:** If the model could infer not just the generated image but also the training data used by the image generation AI, it could contribute even more to protecting creator copyrights.
    

## Acknowledgments

- This project is submitted as the final project for the [Elements of AI - Building AI](https://www.google.com/search?q=https://www.elementsofai.com/build-ai) free online course, provided by the University of Helsinki and Reaktor Innovations.
    
- This idea was inspired while reviewing multimedia-generating AI projects such as [YuE](https://github.com/multimodal-art-projection/YuE), [stable-diffusion](https://github.com/CompVis/stable-diffusion), [vits](https://github.com/jaywalnut310/vits), and **[Bert-VITS2](https://github.com/fishaudio/Bert-VITS2)**.
    
- I believe that a distinction must be made between human creations based on philosophy, emotion, memory, and senses, and the results of AI, which are generated based on probabilistic values from complex calculations. In that sense, I am grateful to the countless authors, producers, cartoonists, film directors, and actors who have moved me. I will strive to protect your intellectual property.
    
- I extend my gratitude to all the engineers who contributed to the related projects that inspired this idea, such as [YuE](https://github.com/multimodal-art-projection/YuE), [stable-diffusion](https://github.com/CompVis/stable-diffusion), [vits](https://github.com/jaywalnut310/vits), and **[Bert-VITS2](https://github.com/fishaudio/Bert-VITS2)**.
